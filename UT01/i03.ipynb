{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "182f0922",
   "metadata": {},
   "source": [
    "# Recolección y preparación de los datos\n",
    "\n",
    "En el corazón del análisis estadístico y la toma de decisiones basada en datos se encuentra un  proceso crítico, pero a menudo subestimado: la recopilación y preparación de datos. Este capítulo se dedica a explorar en profundidad estas etapas fundamentales, reconociendo su papel vital en la determinación de la calidad y eficacia del análisis de datos subsiguiente.\n",
    "\n",
    "La recopilación de datos es mucho más que simplemente reunir información; es una parte funda mental en sí misma que requiere un enfoque metódico y considerado. Los datos recogidos deben  ser no solo relevantes y precisos, sino también representativos de la población o fenómeno en estudio. Este capítulo aborda las diversas metodologías y consideraciones implicadas en la recolección de datos, desde la selección de fuentes adecuadas hasta la implementación de técnicas que aseguren la integridad y la fiabilidad de los datos recopilados.\n",
    "\n",
    "Una vez que los datos son recogidos, el siguiente desafío es prepararlos para el análisis. La preparación de datos es un proceso igualmente crucial, que incluye la limpieza, transformación y organización de los datos en un formato utilizable. A través de ejemplos prácticos y discusiones detalladas, este capítulo guiará al lector en las mejores prácticas y técnicas para la preparación de datos, garantizando que estén listos para una exploración y análisis más profundos.\n",
    "\n",
    "## La importancia de obtener datos y prepararlos\n",
    "\n",
    "El proceso de recopilación de datos, una piedra angular en el análisis estadístico, implica la meticulosa tarea de reunir y medir información para responder interrogantes de investigación y sustentar decisiones informadas. La calidad de los datos recabados es determinante, ya que influirá directamente en la precisión y la fiabilidad de las conclusiones extraídas. Aquí, la máxima *garbage in*, *garbage out* cobra especial relevancia, advirtiendo que la calidad del input determina la del output [11].\n",
    "\n",
    "En el ámbito empresarial, las fuentes de datos son variadas e incluyen registros de ventas, información de clientes, datos financieros, inventarios y métricas de rendimiento, entre otros. La correcta recolección y preparación de estos datos es esencial para obtener insights valiosos y tomar decisiones informadas. Sin embargo, es común encontrar malas prácticas en las empresas, como la falta de estandarización en la captura de datos, almacenamiento en silos departamentales, y registros incompletos o inconsistentes. Por ejemplo, diferentes departamentos pueden utilizar formatos o sistemas distintos para registrar información similar, lo que dificulta la integración y el análisis global. Estas prácticas pueden conducir a errores en el análisis y a conclusiones erróneas. Por ello, es fundamental implementar procesos adecuados de recolección y preparación de datos, alineados con los objetivos específicos de la investigación y con la disponibilidad de recursos, para garantizar la calidad y fiabilidad de los datos utilizados en el análisis.\n",
    "\n",
    "La recopilación de datos de alta calidad es imperativa, requiriendo la definición de criterios claros para la selección de la muestra, el diseño de instrumentos de medición no sesgados y la estandarización de procedimientos para la recolección de datos. Cuando se trabaja con fuentes existentes, es crucial validar la metodología de recolección y asegurar su fiabilidad.\n",
    "\n",
    "El proceso de recopilación puede ser extenso y se debe invertir tiempo considerable en garantizar que los datos sean representativos y precisos. La tarea de recolección y posterior limpieza de datos es esencial, ya que la estructura del análisis y las decisiones que se derivan de este dependen intrínsecamente de la calidad de los datos. Además, es vital recoger los datos de manera ética, respetando la privacidad y autonomía de los participantes [11, 6].\n",
    "\n",
    "Una vez obtenidos, los datos suelen requerir un procesamiento meticuloso para su preparación analítica. La limpieza de datos implica la corrección de errores y la eliminación de incoherencias, mientras que sutransformación asegura la adecuación de los datos para el análisis o la integración de múltiples fuentes en un conjunto coherente de datos.\n",
    "\n",
    "La eficacia en la recopilación de datos es crucial en el proceso de análisis, justificando la inversión de tiempo y recursos para asegurar la alta calidad y relevancia de los datos en relación con los objetivos investigativos o empresariales. Con datos confiables y verídicos en mano, el paso siguiente es su adecuación y preparación para el análisis.\n",
    "\n",
    "La preparación de datos abarca su limpieza, tratamiento y transformación. La limpieza se centra en identificar y rectificar errores, valores omitidos y discrepancias. La eliminación de duplicados, la corrección de errores tipográficos o la imputación de valores faltantes son tareas comunes en este proceso [11].\n",
    "\n",
    "El tratamiento y la transformación de datos adaptan la información a un formato idóneo para el análisis. Esto incluye la combinación de datos de distintas fuentes, la conversión de formatos y la generación de nuevas variables. Las operaciones matemáticas o estadísticas aplicadas durante la transformación de datos pueden revelar nuevas perspectivas o crear variables adicionales, como el cálculo de medias o la normalización de los datos.\n",
    "\n",
    "Para garantizar una recolección y preparación de datos de alta calidad, se recomienda seguir las siguientes prácticas:\n",
    "\n",
    "- Definir objetivos claros: Establecer con precisión las preguntas o metas investigativas orienta la recopilación de datos hacia resultados útiles y pertinentes.\n",
    "- Seleccionar fuentes confiables: Emplear fuentes de datos oficiales o reconocidas contribuye a la precisión y actualización de la información recabada.\n",
    "- Validar los datos: Una verificación previa al análisis asegura la exactitud y completitud de los datos, incluyendo la revisión de valores faltantes o inconsistencias.\n",
    "- Cumplir con estándares de calidad de datos: Adoptar normativas como la ISO 8000-1:2022 garantiza la integridad, exactitud y coherencia de los datos.\n",
    "- Documentar fuentes y métodos: Registrar las fuentes de datos y los procedimientos utilizados en su recolección, limpieza y transformación fomenta la transparencia y teproducibilidad del análisis.\n",
    "\n",
    "## Python\n",
    "\n",
    "Python es un lenguaje de programación potente y cada vez más popular, muy adecuado para el análisis de datos. En primer lugar, Python tiene una sintaxis sencilla e intuitiva que es fácil de aprender, incluso para los principiantes. Esto lo convierte en un lenguaje atractivo para los analistas de datos que no tengan una sólida formación en programación. Con Python, los analistas de datos pueden escribir fácilmente scripts para realizar tareas de limpieza, manipulación y visualización de datos. Además, el paradigma de programación orientada a objetos de Python facilita la organización del código y la escritura de funciones reutilizables, lo que puede resultar especialmente útil para tareas complejas de análisis de datos [12].\n",
    "\n",
    "Otra ventaja de Python es la amplia y activa comunidad de desarrolladores que han creado una gran variedad de bibliotecas y herramientas para el análisis de datos. Esto significa que hay una gran cantidad de recursos disponibles para ayudar a los analistas de datos a iniciarse en Python, así como para resolver problemas y encontrar soluciones. La comunidad Python también ofrece apoyo a través de foros en línea, grupos de usuarios y conferencias, lo que facilita a los analistas de datos la creación de redes y la colaboración con otros profesionales del sector. Muy posiblemente las cosas que se quieran realizar ya estén publicadas en la comunidad y de esta manera se puede agilizar el trabajo [12].\n",
    "\n",
    "Python cuenta con una amplia gama de librerías y herramientas muy usadas para el análisis de datos, como NumPy, Pandas, Matplotlib y SciPy. Estas librerías ofrecen una amplia gama de funcionalidades, desde la manipulación y limpieza de datos hasta la visualización y el análisis estadístico. Por ejemplo, Pandas es una popular librería de Python para la manipulación y el análisis de datos, y proporciona unpotente objeto de marco dedatosparatrabajar con datos tabulares. Por su parte, Matplotlib es una librería de Python muy utilizada para crear visualizaciones de datos de alta calidad. Incluso, a partir de Matplotlib se han creado librerías como Seaborn que facilitan la integración con los DataFrames de pandas [6, 11, 12].\n",
    "\n",
    "Además, Python se puede integrar fácilmente con otros lenguajes y herramientas de programación, lo que lo convierte en una opción ideal para los analistas de datos que trabajan en entornos multilenguaje. Python también puede utilizarse para proyectos de análisis de datos tanto a pequeña como a gran escala. Puede utilizarse para procesar y analizar pequeños conjuntos de datos en unúnico ordenador, así como para procesar y analizar grandes conjuntos de datos en sistemas distribuidos. Esto convierte a Python en una herramienta versátil y escalable para el análisis de datos.\n",
    "\n",
    "En general, la facilidad de uso de Python, su comunidad amplia y activa, su amplia gama de librerías y herramientas, su interoperabilidad y su escalabilidad lo convierten en una opción ideal para el análisis de datos. Python es una potente herramienta que puede ayudar a los analistas de datos a procesar y analizar datos, visualizarlos y obtener información para la toma de decisiones en una amplia gama de campos e industrias.\n",
    "\n",
    "Al buscar datos, se encuentran diferentes tipos de archivos que pueden ser tratados con Python. Algunos de los archivos que pueden aparecer incluyen CSV, Excel, JSON, XML y SQL [6, 11].\n",
    "\n",
    "## Formatos de archivos en el manejo de datos\n",
    "\n",
    "En el análisis y la ciencia de datos, es habitual encontrar distintos tipos de archivos, cada uno con sus propias características y usos. Uno de ellos son los archivos CSV (Comma Separated Value o Valores Separados por Comas), que se utilizan para almacenar datos tabulares en formato de texto. Los archivos CSV pueden manejarse fácilmente con Python utilizando el módulo CSV incorporado o librerías de terceros como Pandas.\n",
    "\n",
    "Otro tipo de archivo habitual en el análisis de datos son los archivos Excel, que son hojas de cálculo creadas con Microsoft Excel. Estos archivos pueden contener varias hojas de cálculo, fórmulas y formatos. Python tiene la librería openpyxl, que permite a los usuarios trabajar con archivos Excel. Los archivos JSON o JavaScript Object Notation son otro tipo de archivo de uso frecuente en el análisis de datos. Los archivos JSON son archivos de texto que utilizan un formato ligero de intercambio de datos, lo que los convierte en una opción ideal para intercambiar datos entre aplicaciones web y almacenar datos de configuración. Python incorpora un módulo json que proporciona métodos para codificar y decodificar datos JSON además se puede utilizar la librería Pandas.\n",
    "\n",
    "Los archivos XML o Extensible Markup Language son archivos de texto que utilizan un lenguaje de marcado para definir elementos y atributos. Se utilizan habitualmente para almacenar e intercambiar datos entre aplicaciones. Python proporciona el módulo xml.etree.ElementTree para analizar y manipular datos XML o también la antes mencionada librería Pandas.\n",
    "\n",
    "Los archivos SQL o Structured Query Language contienen consultas o sentencias SQL que se utilizan para manipular datos en una base de datos. Python proporciona varias bibliotecas para interactuar con bases de datos, incluyendo el módulo incorporado sqlite3, así como bibliotecas de terceros como SQLAlchemy, PyMySQL o Pandas.\n",
    "\n",
    "Python dispone de varias bibliotecas incorporadas y paquetes de terceros para trabajar con estos tipos de archivos. Para leer y manipular archivos CSV, puede utilizar el módulo csv o la popular biblioteca Pandas. Para leer y manipular archivos Excel, puede utilizar la biblioteca openpyxl o Pandas. Para manejar archivos JSON y XML, puedes utilizar los módulos incorporados json, xml.etree.ElementTree o Pandas. Y para trabajar con archivos DB y búsquedas SQL, se puede utilizar el módulo incorporado sqlite3 o bibliotecas de terceros como SQLAlchemy, PyMySQL y Pandas.\n",
    "\n",
    "## Ejemplos\n",
    "\n",
    "Ahora que se ha discutido la importancia de la recopilación de datos y el papel de Python en el análisis de datos, se explorarán algunos tipos de archivos comunes en este contexto y cómo pueden ser manejados mediante el uso de Python. En esta sección, se presentarán ejemplos de cómo pueden ser manejados mediante el uso de Python. En esta sección, se presentarán ejemplos de cómo trabajar con archivos CSV, Excel, JSON, XML y bases de datos utilizando las librerías integradas de Python y paquetes de terceros.\n",
    "\n",
    "Al concluir esta sección, se adquirirá una comprensión sólida de cómo leer, manipular y transformar datos en diversos formatos de archivo mediante el uso de Python. Ya sea que se esté abordando conjuntos de datos extensos o más pequeños, la capacidad para trabajar con una variedad de archivos resulta fundamental para cualquier analista de datos o científico. A continuación, se explorará cómo Python puede ser empleado efectivamente en el manejo de estos formatos comunes de archivos en el contexto del análisis de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f933f1cf",
   "metadata": {},
   "source": [
    "### Formato CSV\n",
    "\n",
    "Los archivos de valores separados por comas (CSV) son un formato de archivo popular para almacenar e intercambiar datos tabulares, como los datos de las hojas de cálculo. Python proporciona un módulo csv integrado que facilita la lectura, escritura y manipulación de archivos CSV.\n",
    "\n",
    "Supóngase que se tiene un archivo CSV llamado \"datos_ventas.csv\" que contiene datos de ventas de una empresa. El archivo tiene cuatro columnas: \"fecha\", \"producto\", \"region_ventas\" y \"cantidad_ventas\". He aquí cómo podemos utilizar Python para leer el archivo y extraer algunos datos:\n",
    "\n",
    "```\n",
    "fecha,producto,region_ventas,cantidad_ventas\n",
    "01/04/2022,Ford,Medellín,24\n",
    "02/04/2022,Pontiac,Medellín,34\n",
    "03/04/2022,Mitsubishi,Pereira,22\n",
    "04/04/2022,Mazda,Pereira,45\n",
    "02/04/2022,Dodge,Bogotá,30\n",
    "02/04/2022,Volkswagen,Bogotá,16\n",
    "01/04/2022,Lexus,Bogotá,14\n",
    "03/04/2022,Cadillac,Bogotá,1\n",
    "03/04/2022,Lexus,Medellín,28\n",
    "01/04/2022,Mitsubishi,Medellín,44\n",
    "02/04/2022,MINI,Bogotá,7\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "becb4bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de ventas: $265.0\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Abre el archivo CSV\n",
    "with open('datos_ventas.csv', 'r') as file:\n",
    "  # Crea un objeto que lee CSV\n",
    "  lector = csv.reader(file)\n",
    "  # Omite el encabezadow\n",
    "  next(lector)\n",
    "  # Recorre las filas y extrae algunas conclusiones\n",
    "  total_ventas = 0\n",
    "  for fila in lector:\n",
    "    cantidad_ventas = float(fila[3])\n",
    "    total_ventas += cantidad_ventas\n",
    "  # Imprime el total de ventas\n",
    "  print(f\"Total de ventas: ${total_ventas}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a37b619",
   "metadata": {},
   "source": [
    "En este ejemplo, primero se importa el módulo CSV y abrimos el archivo CSV utilizando la función open().A continuación, se crea un objeto lector CSV utilizando la función csv.reader() y luego se salta la fila de cabecera utilizando la función next().\n",
    "\n",
    "A continuación, se recorren las filas del archivo y se extrae algunos datos. En este caso, se calculan las ventas totales sumando la columna \"cantidad_ventas\" de cadafila. Se convierte el valor de \"cantidad_ventas\" en un valor flotante utilizando la función float(), ya que los valores se leen inicialmente como cadenas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0019505d",
   "metadata": {},
   "source": [
    "### FormatoExcel\n",
    "\n",
    "Supongamos que ahora tenemos un archivo de Excel llamado \"edades.xlsx\" que contiene una hoja llamada \"Hoja1\" con los siguientes datos:\n",
    "\n",
    "| Nombre  | Edad | Género |\n",
    "| :-----: | :---:| :-----:|\n",
    "| Alice   | 24   | Mujer  |\n",
    "| Bob     | 32   | Hombre |\n",
    "| Charlie | 45   | Hombre |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2315c839",
   "metadata": {},
   "source": [
    "### Formato XML\n",
    "\n",
    "XML (Extensible Markup Language) es un lenguaje de marcado ampliamente utilizado para almacenar e intercambiar datos. Python proporciona varias bibliotecas, como xml.etree.ElementTree y lxml, que facilitan el análisis sintáctico y la manipulación de datos XML.\n",
    "\n",
    "Supongamos que usted está trabajando en un proyecto que involucra el procesamiento de datos de un archivo XML que contiene información sobre una lista de libros. Necesita leer los datos XML, extraer información relevante, realizar tareas de manipulación de datos y generar un informeresumido.\n",
    "\n",
    "Archivo XML: \"libros.xml\":\n",
    "\n",
    "```\n",
    "<libros>\n",
    "    <libro>\n",
    "        <titulo>Python Programming</titulo>\n",
    "        <autor>John Smith</autor>\n",
    "        <genero>Programming</genero>\n",
    "        <precio>29.99</precio>\n",
    "    </libro>\n",
    "    <libro>\n",
    "        <titulo>Data Science for Beginners</titulo>\n",
    "        <autor>Alice Johnson</autor>\n",
    "        <genero>Data Science</genero>\n",
    "        <precio>39.99</precio>\n",
    "    </libro>\n",
    "    <libro>\n",
    "        <titulo>Introduction to Machine Learning</titulo>\n",
    "        <autor>Bob Brown</autor>\n",
    "        <genero>Machine Learning</genero>\n",
    "        <precio>49.99</precio>\n",
    "    </libro>\n",
    "</libros>\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
